
# Gemini API Key (get from https://aistudio.google.com/app/apikey)
GEMINI_API_KEY=your_gemini_api_key_here

# Model to use (default: gemini-2.5-flash)
MODEL_NAME=gemini-2.5-flash

# Temperature controls randomness (0.0-1.0, default: 0.7)
TEMPERATURE=0.7

# Maximum tokens in LLM response (default: 2048)
MAX_TOKENS=2048

# Log level: DEBUG, INFO, WARNING, ERROR (default: INFO)
LOG_LEVEL=INFO
# Log format: json or text (default: json)
LOG_FORMAT=json

# ============================================
# FUTURE USE - API Server Configuration
# ============================================
# Uncomment when FastAPI server is implemented
API_HOST=0.0.0.0
API_PORT=8000
API_WORKERS=1

# ============================================
# FUTURE USE - Rate Limiting
# ============================================
# Uncomment when FastAPI server is implemented
RATE_LIMIT_REQUESTS=10
RATE_LIMIT_PERIOD=1 hour
